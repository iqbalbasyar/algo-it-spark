21/02/25 00:06:08 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:06:08 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:06:08 INFO ResourceUtils: ==============================================================
21/02/25 00:06:08 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:06:08 INFO ResourceUtils: ==============================================================
21/02/25 00:06:08 INFO SparkContext: Submitted application: appName
21/02/25 00:06:08 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:06:08 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:06:08 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:06:08 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:06:08 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:06:08 INFO Utils: Successfully started service 'sparkDriver' on port 53938.
21/02/25 00:06:08 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:06:08 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:06:08 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:06:08 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:06:08 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:06:08 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-f687e6b6-ed7c-4d10-80c0-099368450286
21/02/25 00:06:08 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:06:08 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:06:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/25 00:06:08 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
21/02/25 00:06:08 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:06:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53953.
21/02/25 00:06:08 INFO NettyBlockTransferService: Server created on host.docker.internal:53953
21/02/25 00:06:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:06:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 53953, None)
21/02/25 00:06:08 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:53953 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 53953, None)
21/02/25 00:06:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 53953, None)
21/02/25 00:06:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 53953, None)
21/02/25 00:06:08 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4040
21/02/25 00:06:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/25 00:06:08 INFO MemoryStore: MemoryStore cleared
21/02/25 00:06:08 INFO BlockManager: BlockManager stopped
21/02/25 00:06:08 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/25 00:06:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/25 00:06:08 INFO SparkContext: Successfully stopped SparkContext
21/02/25 00:12:35 INFO ShutdownHookManager: Shutdown hook called
21/02/25 00:12:35 INFO ShutdownHookManager: Deleting directory C:\Users\tomyt\AppData\Local\Temp\spark-fb5e3cfa-adca-4855-8277-96f719f8db5a
21/02/25 00:12:35 INFO ShutdownHookManager: Deleting directory C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-1209fb1d-d5ff-4f8a-a3b1-151958a7e86a
21/02/25 00:12:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/25 00:12:43 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:12:43 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:12:43 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:12:43 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:12:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:12:43 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:12:43 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:12:43 INFO ResourceUtils: ==============================================================
21/02/25 00:12:43 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:12:43 INFO ResourceUtils: ==============================================================
21/02/25 00:12:43 INFO SparkContext: Submitted application: appName
21/02/25 00:12:43 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:12:43 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:12:43 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:12:43 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:12:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:12:44 INFO Utils: Successfully started service 'sparkDriver' on port 54188.
21/02/25 00:12:44 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:12:44 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:12:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:12:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:12:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:12:44 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-d8f61093-4b30-4566-ac30-73ee657a641c
21/02/25 00:12:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:12:44 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:12:44 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/02/25 00:12:44 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
21/02/25 00:12:44 INFO Utils: Successfully started service 'SparkUI' on port 4041.
21/02/25 00:12:44 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4041
21/02/25 00:12:44 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:12:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54203.
21/02/25 00:12:44 INFO NettyBlockTransferService: Server created on host.docker.internal:54203
21/02/25 00:12:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:12:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 54203, None)
21/02/25 00:12:44 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:54203 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 54203, None)
21/02/25 00:12:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 54203, None)
21/02/25 00:12:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 54203, None)
21/02/25 00:15:05 INFO SharedState: loading hive config file: file:/C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/02/25 00:15:05 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive').
21/02/25 00:15:05 INFO SharedState: Warehouse path is 'C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive'.
21/02/25 00:16:18 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
21/02/25 00:16:19 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4041
21/02/25 00:16:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/25 00:16:19 INFO MemoryStore: MemoryStore cleared
21/02/25 00:16:19 INFO BlockManager: BlockManager stopped
21/02/25 00:16:19 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/25 00:16:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/25 00:16:19 INFO SparkContext: Successfully stopped SparkContext
21/02/25 00:16:22 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:16:22 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:16:22 INFO ResourceUtils: ==============================================================
21/02/25 00:16:22 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:16:22 INFO ResourceUtils: ==============================================================
21/02/25 00:16:22 INFO SparkContext: Submitted application: appName
21/02/25 00:16:22 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:16:22 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:16:22 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:16:22 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:16:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:16:22 INFO Utils: Successfully started service 'sparkDriver' on port 54308.
21/02/25 00:16:22 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:16:22 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:16:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:16:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:16:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:16:22 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-db24d8cf-99a8-426a-adf4-9600715a92c2
21/02/25 00:16:22 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:16:22 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:16:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/25 00:16:22 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
21/02/25 00:16:22 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:16:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54323.
21/02/25 00:16:22 INFO NettyBlockTransferService: Server created on host.docker.internal:54323
21/02/25 00:16:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:16:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 54323, None)
21/02/25 00:16:22 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:54323 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 54323, None)
21/02/25 00:16:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 54323, None)
21/02/25 00:16:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 54323, None)
21/02/25 00:20:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/25 00:20:52 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:20:52 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:20:52 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:20:52 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:20:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:20:52 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:20:52 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:20:53 INFO ResourceUtils: ==============================================================
21/02/25 00:20:53 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:20:53 INFO ResourceUtils: ==============================================================
21/02/25 00:20:53 INFO SparkContext: Submitted application: appName
21/02/25 00:20:53 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:20:53 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:20:53 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:20:53 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:20:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:20:53 INFO Utils: Successfully started service 'sparkDriver' on port 54419.
21/02/25 00:20:53 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:20:53 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:20:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:20:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:20:53 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:20:53 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-207e38b8-9780-4b9e-888b-2c242bfe85ac
21/02/25 00:20:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:20:53 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:20:53 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/02/25 00:20:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/25 00:20:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
21/02/25 00:20:53 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:20:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54434.
21/02/25 00:20:53 INFO NettyBlockTransferService: Server created on host.docker.internal:54434
21/02/25 00:20:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:20:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 54434, None)
21/02/25 00:20:53 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:54434 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 54434, None)
21/02/25 00:20:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 54434, None)
21/02/25 00:20:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 54434, None)
21/02/25 00:20:54 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4040
21/02/25 00:20:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/25 00:20:54 INFO MemoryStore: MemoryStore cleared
21/02/25 00:20:54 INFO BlockManager: BlockManager stopped
21/02/25 00:20:54 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/25 00:20:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/25 00:20:54 INFO SparkContext: Successfully stopped SparkContext
21/02/25 00:21:13 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:21:13 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:21:13 INFO ResourceUtils: ==============================================================
21/02/25 00:21:13 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:21:13 INFO ResourceUtils: ==============================================================
21/02/25 00:21:13 INFO SparkContext: Submitted application: appName
21/02/25 00:21:13 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:21:13 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:21:13 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:21:13 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:21:13 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:21:13 INFO Utils: Successfully started service 'sparkDriver' on port 54442.
21/02/25 00:21:13 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:21:13 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:21:13 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:21:13 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:21:13 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:21:13 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-b27a22f7-3156-46d2-8f41-49a31e523c05
21/02/25 00:21:13 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:21:13 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:21:13 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/25 00:21:13 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
21/02/25 00:21:13 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:21:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54457.
21/02/25 00:21:13 INFO NettyBlockTransferService: Server created on host.docker.internal:54457
21/02/25 00:21:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:21:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 54457, None)
21/02/25 00:21:13 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:54457 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 54457, None)
21/02/25 00:21:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 54457, None)
21/02/25 00:21:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 54457, None)
21/02/25 00:21:13 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4040
21/02/25 00:21:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/25 00:21:13 INFO MemoryStore: MemoryStore cleared
21/02/25 00:21:13 INFO BlockManager: BlockManager stopped
21/02/25 00:21:13 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/25 00:21:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/25 00:21:13 INFO SparkContext: Successfully stopped SparkContext
21/02/25 00:21:26 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:21:26 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:21:26 INFO ResourceUtils: ==============================================================
21/02/25 00:21:26 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:21:26 INFO ResourceUtils: ==============================================================
21/02/25 00:21:26 INFO SparkContext: Submitted application: appName
21/02/25 00:21:26 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:21:26 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:21:26 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:21:26 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:21:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:21:26 INFO Utils: Successfully started service 'sparkDriver' on port 54466.
21/02/25 00:21:26 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:21:26 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:21:26 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:21:26 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:21:26 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:21:26 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-b240819a-5aa3-4a16-9a89-5c82178f93f0
21/02/25 00:21:26 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:21:26 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:21:26 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/25 00:21:26 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
21/02/25 00:21:26 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:21:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54481.
21/02/25 00:21:26 INFO NettyBlockTransferService: Server created on host.docker.internal:54481
21/02/25 00:21:26 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:21:26 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 54481, None)
21/02/25 00:21:26 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:54481 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 54481, None)
21/02/25 00:21:26 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 54481, None)
21/02/25 00:21:26 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 54481, None)
21/02/25 00:21:26 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4040
21/02/25 00:21:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/25 00:21:26 INFO MemoryStore: MemoryStore cleared
21/02/25 00:21:26 INFO BlockManager: BlockManager stopped
21/02/25 00:21:26 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/25 00:21:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/25 00:21:26 INFO SparkContext: Successfully stopped SparkContext
21/02/25 00:21:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/02/25 00:21:43 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:21:43 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:21:43 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:21:43 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:21:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:21:43 INFO SparkContext: Running Spark version 3.0.1
21/02/25 00:21:43 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
21/02/25 00:21:43 INFO ResourceUtils: ==============================================================
21/02/25 00:21:43 INFO ResourceUtils: Resources for spark.driver:

21/02/25 00:21:43 INFO ResourceUtils: ==============================================================
21/02/25 00:21:43 INFO SparkContext: Submitted application: appName
21/02/25 00:21:43 INFO SecurityManager: Changing view acls to: tomyt
21/02/25 00:21:43 INFO SecurityManager: Changing modify acls to: tomyt
21/02/25 00:21:43 INFO SecurityManager: Changing view acls groups to: 
21/02/25 00:21:43 INFO SecurityManager: Changing modify acls groups to: 
21/02/25 00:21:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(tomyt); groups with view permissions: Set(); users  with modify permissions: Set(tomyt); groups with modify permissions: Set()
21/02/25 00:21:44 INFO Utils: Successfully started service 'sparkDriver' on port 54545.
21/02/25 00:21:44 INFO SparkEnv: Registering MapOutputTracker
21/02/25 00:21:44 INFO SparkEnv: Registering BlockManagerMaster
21/02/25 00:21:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/02/25 00:21:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/02/25 00:21:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
21/02/25 00:21:44 INFO DiskBlockManager: Created local directory at C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\blockmgr-85febdca-0e39-4336-b8eb-fdb227267376
21/02/25 00:21:44 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
21/02/25 00:21:44 INFO SparkEnv: Registering OutputCommitCoordinator
21/02/25 00:21:44 WARN Utils: The configured local directories are not expected to be URIs; however, got suspicious values [C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/local]. Please check your configured local directories.
21/02/25 00:21:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/02/25 00:21:44 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://host.docker.internal:4040
21/02/25 00:21:44 INFO Executor: Starting executor ID driver on host host.docker.internal
21/02/25 00:21:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54560.
21/02/25 00:21:44 INFO NettyBlockTransferService: Server created on host.docker.internal:54560
21/02/25 00:21:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/02/25 00:21:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, host.docker.internal, 54560, None)
21/02/25 00:21:44 INFO BlockManagerMasterEndpoint: Registering block manager host.docker.internal:54560 with 366.3 MiB RAM, BlockManagerId(driver, host.docker.internal, 54560, None)
21/02/25 00:21:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, host.docker.internal, 54560, None)
21/02/25 00:21:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, host.docker.internal, 54560, None)
21/02/25 00:22:23 INFO SharedState: loading hive config file: file:/C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/conf/hive-site.xml
21/02/25 00:22:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive') to the value of spark.sql.warehouse.dir ('C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive').
21/02/25 00:22:23 INFO SharedState: Warehouse path is 'C:/Users/tomyt/AppData/Local/spark/spark-3.0.1-bin-hadoop3.2/tmp/hive'.
21/02/25 00:34:36 INFO SparkContext: Starting job: collect at <ipython-input-15-692558e6adf3>:1
21/02/25 00:34:36 INFO DAGScheduler: Got job 0 (collect at <ipython-input-15-692558e6adf3>:1) with 1 output partitions
21/02/25 00:34:36 INFO DAGScheduler: Final stage: ResultStage 0 (collect at <ipython-input-15-692558e6adf3>:1)
21/02/25 00:34:36 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:34:36 INFO DAGScheduler: Missing parents: List()
21/02/25 00:34:36 INFO DAGScheduler: Submitting ResultStage 0 (PythonRDD[2] at collect at <ipython-input-15-692558e6adf3>:1), which has no missing parents
21/02/25 00:34:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.8 KiB, free 366.3 MiB)
21/02/25 00:34:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 366.3 MiB)
21/02/25 00:34:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on host.docker.internal:54560 (size: 3.2 KiB, free: 366.3 MiB)
21/02/25 00:34:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1223
21/02/25 00:34:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (PythonRDD[2] at collect at <ipython-input-15-692558e6adf3>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:34:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/02/25 00:34:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7407 bytes)
21/02/25 00:34:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/02/25 00:34:37 ERROR Executor: Exception in task 0.0 in stage 0.0 (TID 0)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
TypeError: get_dayname() missing 1 required positional argument: 'fmt'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/02/25 00:34:37 WARN TaskSetManager: Lost task 0.0 in stage 0.0 (TID 0, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
TypeError: get_dayname() missing 1 required positional argument: 'fmt'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

21/02/25 00:34:37 ERROR TaskSetManager: Task 0 in stage 0.0 failed 1 times; aborting job
21/02/25 00:34:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/02/25 00:34:37 INFO TaskSchedulerImpl: Cancelling stage 0
21/02/25 00:34:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage cancelled
21/02/25 00:34:37 INFO DAGScheduler: ResultStage 0 (collect at <ipython-input-15-692558e6adf3>:1) failed in 0.984 s due to Job aborted due to stage failure: Task 0 in stage 0.0 failed 1 times, most recent failure: Lost task 0.0 in stage 0.0 (TID 0, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
TypeError: get_dayname() missing 1 required positional argument: 'fmt'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
21/02/25 00:34:37 INFO DAGScheduler: Job 0 failed: collect at <ipython-input-15-692558e6adf3>:1, took 1.013344 s
21/02/25 00:36:11 INFO SparkContext: Starting job: collect at <ipython-input-16-f88d9a72b805>:1
21/02/25 00:36:11 INFO DAGScheduler: Got job 1 (collect at <ipython-input-16-f88d9a72b805>:1) with 1 output partitions
21/02/25 00:36:11 INFO DAGScheduler: Final stage: ResultStage 1 (collect at <ipython-input-16-f88d9a72b805>:1)
21/02/25 00:36:11 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:36:11 INFO DAGScheduler: Missing parents: List()
21/02/25 00:36:11 INFO DAGScheduler: Submitting ResultStage 1 (PythonRDD[3] at collect at <ipython-input-16-f88d9a72b805>:1), which has no missing parents
21/02/25 00:36:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KiB, free 366.3 MiB)
21/02/25 00:36:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:36:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:36:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1223
21/02/25 00:36:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (PythonRDD[3] at collect at <ipython-input-16-f88d9a72b805>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:36:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/02/25 00:36:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7407 bytes)
21/02/25 00:36:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/02/25 00:36:12 INFO PythonRunner: Times: total = 370, boot = 353, init = 5, finish = 12
21/02/25 00:36:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1519 bytes result sent to driver
21/02/25 00:36:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 397 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:36:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/02/25 00:36:12 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 54561
21/02/25 00:36:12 INFO DAGScheduler: ResultStage 1 (collect at <ipython-input-16-f88d9a72b805>:1) finished in 0.415 s
21/02/25 00:36:12 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:36:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
21/02/25 00:36:12 INFO DAGScheduler: Job 1 finished: collect at <ipython-input-16-f88d9a72b805>:1, took 0.420888 s
21/02/25 00:38:49 INFO SparkContext: Starting job: collect at <ipython-input-20-4d8d7546908f>:2
21/02/25 00:38:49 INFO DAGScheduler: Got job 2 (collect at <ipython-input-20-4d8d7546908f>:2) with 1 output partitions
21/02/25 00:38:49 INFO DAGScheduler: Final stage: ResultStage 2 (collect at <ipython-input-20-4d8d7546908f>:2)
21/02/25 00:38:49 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:38:49 INFO DAGScheduler: Missing parents: List()
21/02/25 00:38:49 INFO DAGScheduler: Submitting ResultStage 2 (PythonRDD[4] at collect at <ipython-input-20-4d8d7546908f>:2), which has no missing parents
21/02/25 00:38:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.9 KiB, free 366.3 MiB)
21/02/25 00:38:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:38:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:38:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1223
21/02/25 00:38:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (PythonRDD[4] at collect at <ipython-input-20-4d8d7546908f>:2) (first 15 tasks are for partitions Vector(0))
21/02/25 00:38:49 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/02/25 00:38:49 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7407 bytes)
21/02/25 00:38:49 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/02/25 00:38:49 INFO PythonRunner: Times: total = 346, boot = 346, init = 0, finish = 0
21/02/25 00:38:49 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1519 bytes result sent to driver
21/02/25 00:38:49 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 351 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:38:49 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/02/25 00:38:49 INFO DAGScheduler: ResultStage 2 (collect at <ipython-input-20-4d8d7546908f>:2) finished in 0.360 s
21/02/25 00:38:49 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:38:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
21/02/25 00:38:49 INFO DAGScheduler: Job 2 finished: collect at <ipython-input-20-4d8d7546908f>:2, took 0.374405 s
21/02/25 00:40:33 INFO SparkContext: Starting job: collect at <ipython-input-25-695e29536908>:1
21/02/25 00:40:33 INFO DAGScheduler: Got job 3 (collect at <ipython-input-25-695e29536908>:1) with 1 output partitions
21/02/25 00:40:33 INFO DAGScheduler: Final stage: ResultStage 3 (collect at <ipython-input-25-695e29536908>:1)
21/02/25 00:40:33 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:40:33 INFO DAGScheduler: Missing parents: List()
21/02/25 00:40:33 INFO DAGScheduler: Submitting ResultStage 3 (PythonRDD[5] at collect at <ipython-input-25-695e29536908>:1), which has no missing parents
21/02/25 00:40:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 4.9 KiB, free 366.3 MiB)
21/02/25 00:40:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:40:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:40:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1223
21/02/25 00:40:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (PythonRDD[5] at collect at <ipython-input-25-695e29536908>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:40:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
21/02/25 00:40:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7407 bytes)
21/02/25 00:40:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
21/02/25 00:40:33 INFO PythonRunner: Times: total = 349, boot = 333, init = 16, finish = 0
21/02/25 00:40:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1519 bytes result sent to driver
21/02/25 00:40:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 349 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:40:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
21/02/25 00:40:33 INFO DAGScheduler: ResultStage 3 (collect at <ipython-input-25-695e29536908>:1) finished in 0.349 s
21/02/25 00:40:33 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:40:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
21/02/25 00:40:33 INFO DAGScheduler: Job 3 finished: collect at <ipython-input-25-695e29536908>:1, took 0.355989 s
21/02/25 00:41:10 INFO SparkContext: Starting job: collect at <ipython-input-27-edc8eb7b5185>:1
21/02/25 00:41:10 INFO DAGScheduler: Got job 4 (collect at <ipython-input-27-edc8eb7b5185>:1) with 1 output partitions
21/02/25 00:41:10 INFO DAGScheduler: Final stage: ResultStage 4 (collect at <ipython-input-27-edc8eb7b5185>:1)
21/02/25 00:41:10 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:41:10 INFO DAGScheduler: Missing parents: List()
21/02/25 00:41:10 INFO DAGScheduler: Submitting ResultStage 4 (ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262), which has no missing parents
21/02/25 00:41:10 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 2.0 KiB, free 366.3 MiB)
21/02/25 00:41:10 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1257.0 B, free 366.3 MiB)
21/02/25 00:41:10 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on host.docker.internal:54560 (size: 1257.0 B, free: 366.3 MiB)
21/02/25 00:41:10 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1223
21/02/25 00:41:10 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:262) (first 15 tasks are for partitions Vector(0))
21/02/25 00:41:10 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
21/02/25 00:41:10 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7407 bytes)
21/02/25 00:41:10 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
21/02/25 00:41:10 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 779 bytes result sent to driver
21/02/25 00:41:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 3 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:41:10 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
21/02/25 00:41:10 INFO DAGScheduler: ResultStage 4 (collect at <ipython-input-27-edc8eb7b5185>:1) finished in 0.010 s
21/02/25 00:41:10 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:41:10 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
21/02/25 00:41:10 INFO DAGScheduler: Job 4 finished: collect at <ipython-input-27-edc8eb7b5185>:1, took 0.014719 s
21/02/25 00:48:24 INFO BlockManagerInfo: Removed broadcast_1_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:48:24 INFO BlockManagerInfo: Removed broadcast_4_piece0 on host.docker.internal:54560 in memory (size: 1257.0 B, free: 366.3 MiB)
21/02/25 00:48:24 INFO BlockManagerInfo: Removed broadcast_0_piece0 on host.docker.internal:54560 in memory (size: 3.2 KiB, free: 366.3 MiB)
21/02/25 00:48:24 INFO BlockManagerInfo: Removed broadcast_2_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:48:24 INFO BlockManagerInfo: Removed broadcast_3_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:48:44 INFO SparkContext: Starting job: collect at <ipython-input-37-7e2cf473c48d>:1
21/02/25 00:48:44 INFO DAGScheduler: Got job 5 (collect at <ipython-input-37-7e2cf473c48d>:1) with 1 output partitions
21/02/25 00:48:44 INFO DAGScheduler: Final stage: ResultStage 5 (collect at <ipython-input-37-7e2cf473c48d>:1)
21/02/25 00:48:44 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:48:44 INFO DAGScheduler: Missing parents: List()
21/02/25 00:48:44 INFO DAGScheduler: Submitting ResultStage 5 (PythonRDD[8] at collect at <ipython-input-37-7e2cf473c48d>:1), which has no missing parents
21/02/25 00:48:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.0 KiB, free 366.3 MiB)
21/02/25 00:48:45 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:48:45 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:48:45 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1223
21/02/25 00:48:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (PythonRDD[8] at collect at <ipython-input-37-7e2cf473c48d>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:48:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
21/02/25 00:48:45 WARN TaskSetManager: Stage 5 contains a task of very large size (123197 KiB). The maximum recommended task size is 1000 KiB.
21/02/25 00:48:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 126154100 bytes)
21/02/25 00:48:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
21/02/25 00:48:45 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 5)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-24-f3651186ea3b>", line 1, in <lambda>
  File "<ipython-input-11-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '2020-01-01 00:28:15' does not match format '%m/%d/%Y %H:%M'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/02/25 00:48:45 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 5, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-24-f3651186ea3b>", line 1, in <lambda>
  File "<ipython-input-11-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '2020-01-01 00:28:15' does not match format '%m/%d/%Y %H:%M'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

21/02/25 00:48:45 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job
21/02/25 00:48:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
21/02/25 00:48:45 INFO TaskSchedulerImpl: Cancelling stage 5
21/02/25 00:48:45 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage cancelled
21/02/25 00:48:45 INFO DAGScheduler: ResultStage 5 (collect at <ipython-input-37-7e2cf473c48d>:1) failed in 0.789 s due to Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 5, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-24-f3651186ea3b>", line 1, in <lambda>
  File "<ipython-input-11-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '2020-01-01 00:28:15' does not match format '%m/%d/%Y %H:%M'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
21/02/25 00:48:45 INFO DAGScheduler: Job 5 failed: collect at <ipython-input-37-7e2cf473c48d>:1, took 0.792161 s
21/02/25 00:49:48 INFO SparkContext: Starting job: collect at <ipython-input-43-695e29536908>:1
21/02/25 00:49:48 INFO DAGScheduler: Got job 6 (collect at <ipython-input-43-695e29536908>:1) with 1 output partitions
21/02/25 00:49:48 INFO DAGScheduler: Final stage: ResultStage 6 (collect at <ipython-input-43-695e29536908>:1)
21/02/25 00:49:48 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:49:48 INFO DAGScheduler: Missing parents: List()
21/02/25 00:49:48 INFO DAGScheduler: Submitting ResultStage 6 (PythonRDD[10] at collect at <ipython-input-43-695e29536908>:1), which has no missing parents
21/02/25 00:49:48 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 4.9 KiB, free 366.3 MiB)
21/02/25 00:49:48 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:49:48 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:49:48 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1223
21/02/25 00:49:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (PythonRDD[10] at collect at <ipython-input-43-695e29536908>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:49:48 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
21/02/25 00:49:48 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7410 bytes)
21/02/25 00:49:48 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
21/02/25 00:49:48 INFO PythonRunner: Times: total = 467, boot = 463, init = 1, finish = 3
21/02/25 00:49:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1476 bytes result sent to driver
21/02/25 00:49:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 478 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:49:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
21/02/25 00:49:48 INFO DAGScheduler: ResultStage 6 (collect at <ipython-input-43-695e29536908>:1) finished in 0.486 s
21/02/25 00:49:48 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:49:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
21/02/25 00:49:48 INFO DAGScheduler: Job 6 finished: collect at <ipython-input-43-695e29536908>:1, took 0.490255 s
21/02/25 00:49:49 INFO SparkContext: Starting job: collect at <ipython-input-44-edc8eb7b5185>:1
21/02/25 00:49:49 INFO DAGScheduler: Got job 7 (collect at <ipython-input-44-edc8eb7b5185>:1) with 1 output partitions
21/02/25 00:49:49 INFO DAGScheduler: Final stage: ResultStage 7 (collect at <ipython-input-44-edc8eb7b5185>:1)
21/02/25 00:49:49 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:49:49 INFO DAGScheduler: Missing parents: List()
21/02/25 00:49:49 INFO DAGScheduler: Submitting ResultStage 7 (ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:262), which has no missing parents
21/02/25 00:49:49 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.0 KiB, free 366.3 MiB)
21/02/25 00:49:49 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1258.0 B, free 366.3 MiB)
21/02/25 00:49:49 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on host.docker.internal:54560 (size: 1258.0 B, free: 366.3 MiB)
21/02/25 00:49:49 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1223
21/02/25 00:49:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:262) (first 15 tasks are for partitions Vector(0))
21/02/25 00:49:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
21/02/25 00:49:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7410 bytes)
21/02/25 00:49:49 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
21/02/25 00:49:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 782 bytes result sent to driver
21/02/25 00:49:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 6 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:49:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
21/02/25 00:49:49 INFO DAGScheduler: ResultStage 7 (collect at <ipython-input-44-edc8eb7b5185>:1) finished in 0.011 s
21/02/25 00:49:49 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:49:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 7: Stage finished
21/02/25 00:49:49 INFO DAGScheduler: Job 7 finished: collect at <ipython-input-44-edc8eb7b5185>:1, took 0.013031 s
21/02/25 00:50:03 INFO BlockManagerInfo: Removed broadcast_7_piece0 on host.docker.internal:54560 in memory (size: 1258.0 B, free: 366.3 MiB)
21/02/25 00:50:03 INFO BlockManagerInfo: Removed broadcast_6_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:50:03 INFO BlockManagerInfo: Removed broadcast_5_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:50:03 INFO SparkContext: Starting job: collect at <ipython-input-46-7e2cf473c48d>:1
21/02/25 00:50:03 INFO DAGScheduler: Got job 8 (collect at <ipython-input-46-7e2cf473c48d>:1) with 1 output partitions
21/02/25 00:50:03 INFO DAGScheduler: Final stage: ResultStage 8 (collect at <ipython-input-46-7e2cf473c48d>:1)
21/02/25 00:50:03 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:50:03 INFO DAGScheduler: Missing parents: List()
21/02/25 00:50:03 INFO DAGScheduler: Submitting ResultStage 8 (PythonRDD[12] at collect at <ipython-input-46-7e2cf473c48d>:1), which has no missing parents
21/02/25 00:50:03 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 5.0 KiB, free 366.3 MiB)
21/02/25 00:50:03 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:50:03 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:50:03 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1223
21/02/25 00:50:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (PythonRDD[12] at collect at <ipython-input-46-7e2cf473c48d>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:50:03 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
21/02/25 00:50:03 WARN TaskSetManager: Stage 8 contains a task of very large size (123197 KiB). The maximum recommended task size is 1000 KiB.
21/02/25 00:50:03 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 126154100 bytes)
21/02/25 00:50:03 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
21/02/25 00:50:04 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 8)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-42-43ac618da581>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '2020-01-01 00:28:15' does not match format '%m-%d-%Y %H:%M'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/02/25 00:50:04 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 8, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-42-43ac618da581>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '2020-01-01 00:28:15' does not match format '%m-%d-%Y %H:%M'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

21/02/25 00:50:04 ERROR TaskSetManager: Task 0 in stage 8.0 failed 1 times; aborting job
21/02/25 00:50:04 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
21/02/25 00:50:04 INFO TaskSchedulerImpl: Cancelling stage 8
21/02/25 00:50:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage cancelled
21/02/25 00:50:04 INFO DAGScheduler: ResultStage 8 (collect at <ipython-input-46-7e2cf473c48d>:1) failed in 0.592 s due to Job aborted due to stage failure: Task 0 in stage 8.0 failed 1 times, most recent failure: Lost task 0.0 in stage 8.0 (TID 8, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-42-43ac618da581>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '2020-01-01 00:28:15' does not match format '%m-%d-%Y %H:%M'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
21/02/25 00:50:04 INFO DAGScheduler: Job 8 failed: collect at <ipython-input-46-7e2cf473c48d>:1, took 0.579720 s
21/02/25 00:51:26 INFO SparkContext: Starting job: collect at <ipython-input-51-695e29536908>:1
21/02/25 00:51:26 INFO DAGScheduler: Got job 9 (collect at <ipython-input-51-695e29536908>:1) with 1 output partitions
21/02/25 00:51:26 INFO DAGScheduler: Final stage: ResultStage 9 (collect at <ipython-input-51-695e29536908>:1)
21/02/25 00:51:26 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:51:26 INFO DAGScheduler: Missing parents: List()
21/02/25 00:51:26 INFO DAGScheduler: Submitting ResultStage 9 (PythonRDD[13] at collect at <ipython-input-51-695e29536908>:1), which has no missing parents
21/02/25 00:51:26 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 4.9 KiB, free 366.3 MiB)
21/02/25 00:51:26 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:51:26 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:51:26 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1223
21/02/25 00:51:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (PythonRDD[13] at collect at <ipython-input-51-695e29536908>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:51:26 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
21/02/25 00:51:26 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7410 bytes)
21/02/25 00:51:26 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
21/02/25 00:51:26 INFO PythonRunner: Times: total = 456, boot = 448, init = 2, finish = 6
21/02/25 00:51:26 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 1476 bytes result sent to driver
21/02/25 00:51:26 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 472 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:51:26 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
21/02/25 00:51:26 INFO DAGScheduler: ResultStage 9 (collect at <ipython-input-51-695e29536908>:1) finished in 0.480 s
21/02/25 00:51:26 INFO DAGScheduler: Job 9 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:51:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
21/02/25 00:51:26 INFO DAGScheduler: Job 9 finished: collect at <ipython-input-51-695e29536908>:1, took 0.482829 s
21/02/25 00:51:28 INFO SparkContext: Starting job: collect at <ipython-input-52-edc8eb7b5185>:1
21/02/25 00:51:28 INFO DAGScheduler: Got job 10 (collect at <ipython-input-52-edc8eb7b5185>:1) with 1 output partitions
21/02/25 00:51:28 INFO DAGScheduler: Final stage: ResultStage 10 (collect at <ipython-input-52-edc8eb7b5185>:1)
21/02/25 00:51:28 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:51:28 INFO DAGScheduler: Missing parents: List()
21/02/25 00:51:28 INFO DAGScheduler: Submitting ResultStage 10 (ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:262), which has no missing parents
21/02/25 00:51:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 2.0 KiB, free 366.3 MiB)
21/02/25 00:51:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 1258.0 B, free 366.3 MiB)
21/02/25 00:51:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on host.docker.internal:54560 (size: 1258.0 B, free: 366.3 MiB)
21/02/25 00:51:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1223
21/02/25 00:51:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (ParallelCollectionRDD[9] at readRDDFromFile at PythonRDD.scala:262) (first 15 tasks are for partitions Vector(0))
21/02/25 00:51:28 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
21/02/25 00:51:28 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7410 bytes)
21/02/25 00:51:28 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
21/02/25 00:51:28 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 782 bytes result sent to driver
21/02/25 00:51:28 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 2 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:51:28 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
21/02/25 00:51:28 INFO DAGScheduler: ResultStage 10 (collect at <ipython-input-52-edc8eb7b5185>:1) finished in 0.006 s
21/02/25 00:51:28 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:51:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 10: Stage finished
21/02/25 00:51:28 INFO DAGScheduler: Job 10 finished: collect at <ipython-input-52-edc8eb7b5185>:1, took 0.008655 s
21/02/25 00:51:45 INFO BlockManagerInfo: Removed broadcast_9_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:51:45 INFO BlockManagerInfo: Removed broadcast_10_piece0 on host.docker.internal:54560 in memory (size: 1258.0 B, free: 366.3 MiB)
21/02/25 00:51:45 INFO BlockManagerInfo: Removed broadcast_8_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:51:57 INFO SparkContext: Starting job: collect at <ipython-input-57-7e2cf473c48d>:1
21/02/25 00:51:57 INFO DAGScheduler: Got job 11 (collect at <ipython-input-57-7e2cf473c48d>:1) with 1 output partitions
21/02/25 00:51:57 INFO DAGScheduler: Final stage: ResultStage 11 (collect at <ipython-input-57-7e2cf473c48d>:1)
21/02/25 00:51:57 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:51:57 INFO DAGScheduler: Missing parents: List()
21/02/25 00:51:57 INFO DAGScheduler: Submitting ResultStage 11 (PythonRDD[15] at collect at <ipython-input-57-7e2cf473c48d>:1), which has no missing parents
21/02/25 00:51:57 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 5.0 KiB, free 366.3 MiB)
21/02/25 00:51:57 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:51:57 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:51:57 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1223
21/02/25 00:51:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (PythonRDD[15] at collect at <ipython-input-57-7e2cf473c48d>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:51:57 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
21/02/25 00:51:57 WARN TaskSetManager: Stage 11 contains a task of very large size (123197 KiB). The maximum recommended task size is 1000 KiB.
21/02/25 00:51:57 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 126154100 bytes)
21/02/25 00:51:57 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
21/02/25 00:51:57 ERROR Executor: Exception in task 0.0 in stage 11.0 (TID 11)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-54-951e472d168f>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 352, in _strptime
    raise ValueError("unconverted data remains: %s" %
ValueError: unconverted data remains: :15

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/02/25 00:51:57 WARN TaskSetManager: Lost task 0.0 in stage 11.0 (TID 11, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-54-951e472d168f>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 352, in _strptime
    raise ValueError("unconverted data remains: %s" %
ValueError: unconverted data remains: :15

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

21/02/25 00:51:57 ERROR TaskSetManager: Task 0 in stage 11.0 failed 1 times; aborting job
21/02/25 00:51:57 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
21/02/25 00:51:57 INFO TaskSchedulerImpl: Cancelling stage 11
21/02/25 00:51:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage cancelled
21/02/25 00:51:57 INFO DAGScheduler: ResultStage 11 (collect at <ipython-input-57-7e2cf473c48d>:1) failed in 0.672 s due to Job aborted due to stage failure: Task 0 in stage 11.0 failed 1 times, most recent failure: Lost task 0.0 in stage 11.0 (TID 11, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-54-951e472d168f>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 352, in _strptime
    raise ValueError("unconverted data remains: %s" %
ValueError: unconverted data remains: :15

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
21/02/25 00:51:57 INFO DAGScheduler: Job 11 failed: collect at <ipython-input-57-7e2cf473c48d>:1, took 0.688025 s
21/02/25 00:54:13 INFO SparkContext: Starting job: collect at <ipython-input-61-695e29536908>:1
21/02/25 00:54:13 INFO DAGScheduler: Got job 12 (collect at <ipython-input-61-695e29536908>:1) with 1 output partitions
21/02/25 00:54:13 INFO DAGScheduler: Final stage: ResultStage 12 (collect at <ipython-input-61-695e29536908>:1)
21/02/25 00:54:13 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:54:13 INFO DAGScheduler: Missing parents: List()
21/02/25 00:54:13 INFO DAGScheduler: Submitting ResultStage 12 (PythonRDD[16] at collect at <ipython-input-61-695e29536908>:1), which has no missing parents
21/02/25 00:54:13 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 5.0 KiB, free 366.3 MiB)
21/02/25 00:54:13 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:54:13 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:54:13 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1223
21/02/25 00:54:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (PythonRDD[16] at collect at <ipython-input-61-695e29536908>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:54:13 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
21/02/25 00:54:13 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7410 bytes)
21/02/25 00:54:13 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
21/02/25 00:54:14 ERROR Executor: Exception in task 0.0 in stage 12.0 (TID 12)
org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-60-998593d20033>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '1-1-2020 01:01' does not match format '%Y-%m-%d %H:%M:%S'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
21/02/25 00:54:14 WARN TaskSetManager: Lost task 0.0 in stage 12.0 (TID 12, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-60-998593d20033>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '1-1-2020 01:01' does not match format '%Y-%m-%d %H:%M:%S'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

21/02/25 00:54:14 ERROR TaskSetManager: Task 0 in stage 12.0 failed 1 times; aborting job
21/02/25 00:54:14 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
21/02/25 00:54:14 INFO TaskSchedulerImpl: Cancelling stage 12
21/02/25 00:54:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage cancelled
21/02/25 00:54:14 INFO DAGScheduler: ResultStage 12 (collect at <ipython-input-61-695e29536908>:1) failed in 0.477 s due to Job aborted due to stage failure: Task 0 in stage 12.0 failed 1 times, most recent failure: Lost task 0.0 in stage 12.0 (TID 12, host.docker.internal, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 605, in main
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\worker.py", line 597, in process
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\serializers.py", line 271, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\python\lib\pyspark.zip\pyspark\util.py", line 107, in wrapper
    return f(*args, **kwargs)
  File "<ipython-input-60-998593d20033>", line 1, in <lambda>
  File "<ipython-input-40-77a1e98309ea>", line 3, in get_dayname
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "c:\users\tomyt\anaconda3\envs\py-spark\lib\_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data '1-1-2020 01:01' does not match format '%Y-%m-%d %H:%M:%S'

	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:503)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:638)
	at org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:621)
	at org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:456)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)
	at scala.collection.Iterator.foreach(Iterator.scala:941)
	at scala.collection.Iterator.foreach$(Iterator.scala:941)
	at org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)
	at scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)
	at scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)
	at scala.collection.TraversableOnce.to(TraversableOnce.scala:315)
	at scala.collection.TraversableOnce.to$(TraversableOnce.scala:313)
	at org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:307)
	at scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:307)
	at org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)
	at scala.collection.TraversableOnce.toArray(TraversableOnce.scala:294)
	at scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:288)
	at org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)
	at org.apache.spark.rdd.RDD.$anonfun$collect$2(RDD.scala:1004)
	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2139)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)
	at org.apache.spark.scheduler.Task.run(Task.scala:127)
	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:446)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1377)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:449)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

Driver stacktrace:
21/02/25 00:54:14 INFO DAGScheduler: Job 12 failed: collect at <ipython-input-61-695e29536908>:1, took 0.482857 s
21/02/25 00:54:27 INFO BlockManagerInfo: Removed broadcast_11_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:54:27 INFO BlockManagerInfo: Removed broadcast_12_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:54:27 INFO SparkContext: Starting job: collect at <ipython-input-70-695e29536908>:1
21/02/25 00:54:27 INFO DAGScheduler: Got job 13 (collect at <ipython-input-70-695e29536908>:1) with 1 output partitions
21/02/25 00:54:27 INFO DAGScheduler: Final stage: ResultStage 13 (collect at <ipython-input-70-695e29536908>:1)
21/02/25 00:54:27 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:54:27 INFO DAGScheduler: Missing parents: List()
21/02/25 00:54:27 INFO DAGScheduler: Submitting ResultStage 13 (PythonRDD[18] at collect at <ipython-input-70-695e29536908>:1), which has no missing parents
21/02/25 00:54:27 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 5.0 KiB, free 366.3 MiB)
21/02/25 00:54:27 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:54:27 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:54:27 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1223
21/02/25 00:54:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (PythonRDD[18] at collect at <ipython-input-70-695e29536908>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:54:27 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
21/02/25 00:54:27 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7425 bytes)
21/02/25 00:54:27 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
21/02/25 00:54:27 INFO PythonRunner: Times: total = 479, boot = 475, init = 1, finish = 3
21/02/25 00:54:27 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1476 bytes result sent to driver
21/02/25 00:54:27 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 494 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:54:27 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
21/02/25 00:54:27 INFO DAGScheduler: ResultStage 13 (collect at <ipython-input-70-695e29536908>:1) finished in 0.495 s
21/02/25 00:54:27 INFO DAGScheduler: Job 13 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:54:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 13: Stage finished
21/02/25 00:54:27 INFO DAGScheduler: Job 13 finished: collect at <ipython-input-70-695e29536908>:1, took 0.488651 s
21/02/25 00:54:28 INFO SparkContext: Starting job: collect at <ipython-input-71-edc8eb7b5185>:1
21/02/25 00:54:28 INFO DAGScheduler: Got job 14 (collect at <ipython-input-71-edc8eb7b5185>:1) with 1 output partitions
21/02/25 00:54:28 INFO DAGScheduler: Final stage: ResultStage 14 (collect at <ipython-input-71-edc8eb7b5185>:1)
21/02/25 00:54:28 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:54:28 INFO DAGScheduler: Missing parents: List()
21/02/25 00:54:28 INFO DAGScheduler: Submitting ResultStage 14 (ParallelCollectionRDD[17] at readRDDFromFile at PythonRDD.scala:262), which has no missing parents
21/02/25 00:54:28 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 2.0 KiB, free 366.3 MiB)
21/02/25 00:54:28 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 1258.0 B, free 366.3 MiB)
21/02/25 00:54:28 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on host.docker.internal:54560 (size: 1258.0 B, free: 366.3 MiB)
21/02/25 00:54:28 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1223
21/02/25 00:54:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (ParallelCollectionRDD[17] at readRDDFromFile at PythonRDD.scala:262) (first 15 tasks are for partitions Vector(0))
21/02/25 00:54:28 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
21/02/25 00:54:28 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, host.docker.internal, executor driver, partition 0, PROCESS_LOCAL, 7425 bytes)
21/02/25 00:54:28 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
21/02/25 00:54:28 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 754 bytes result sent to driver
21/02/25 00:54:28 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 2 ms on host.docker.internal (executor driver) (1/1)
21/02/25 00:54:28 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
21/02/25 00:54:28 INFO DAGScheduler: ResultStage 14 (collect at <ipython-input-71-edc8eb7b5185>:1) finished in 0.006 s
21/02/25 00:54:28 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
21/02/25 00:54:28 INFO TaskSchedulerImpl: Killing all running tasks in stage 14: Stage finished
21/02/25 00:54:28 INFO DAGScheduler: Job 14 finished: collect at <ipython-input-71-edc8eb7b5185>:1, took 0.008564 s
21/02/25 00:54:33 INFO BlockManagerInfo: Removed broadcast_14_piece0 on host.docker.internal:54560 in memory (size: 1258.0 B, free: 366.3 MiB)
21/02/25 00:54:33 INFO BlockManagerInfo: Removed broadcast_13_piece0 on host.docker.internal:54560 in memory (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:54:34 INFO SparkContext: Starting job: collect at <ipython-input-73-7e2cf473c48d>:1
21/02/25 00:54:34 INFO DAGScheduler: Got job 15 (collect at <ipython-input-73-7e2cf473c48d>:1) with 1 output partitions
21/02/25 00:54:34 INFO DAGScheduler: Final stage: ResultStage 15 (collect at <ipython-input-73-7e2cf473c48d>:1)
21/02/25 00:54:34 INFO DAGScheduler: Parents of final stage: List()
21/02/25 00:54:34 INFO DAGScheduler: Missing parents: List()
21/02/25 00:54:34 INFO DAGScheduler: Submitting ResultStage 15 (PythonRDD[20] at collect at <ipython-input-73-7e2cf473c48d>:1), which has no missing parents
21/02/25 00:54:34 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 5.0 KiB, free 366.3 MiB)
21/02/25 00:54:34 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.3 KiB, free 366.3 MiB)
21/02/25 00:54:34 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on host.docker.internal:54560 (size: 3.3 KiB, free: 366.3 MiB)
21/02/25 00:54:34 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1223
21/02/25 00:54:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (PythonRDD[20] at collect at <ipython-input-73-7e2cf473c48d>:1) (first 15 tasks are for partitions Vector(0))
21/02/25 00:54:34 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
21/02/25 01:01:24 INFO SparkContext: Invoking stop() from shutdown hook
21/02/25 01:01:24 INFO SparkUI: Stopped Spark web UI at http://host.docker.internal:4040
21/02/25 01:01:24 INFO DAGScheduler: Job 15 failed: collect at <ipython-input-73-7e2cf473c48d>:1, took 410.767493 s
21/02/25 01:01:24 INFO DAGScheduler: ResultStage 15 (collect at <ipython-input-73-7e2cf473c48d>:1) failed in 410.773 s due to Stage cancelled because SparkContext was shut down
21/02/25 01:01:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/02/25 01:01:24 INFO MemoryStore: MemoryStore cleared
21/02/25 01:01:24 INFO BlockManager: BlockManager stopped
21/02/25 01:01:24 INFO BlockManagerMaster: BlockManagerMaster stopped
21/02/25 01:01:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/02/25 01:01:24 INFO SparkContext: Successfully stopped SparkContext
21/02/25 01:01:24 INFO ShutdownHookManager: Shutdown hook called
21/02/25 01:01:24 INFO ShutdownHookManager: Deleting directory C:\Users\tomyt\AppData\Local\Temp\spark-14b979af-ca86-4c9c-8e8f-fdeee9f4b097
21/02/25 01:01:24 INFO ShutdownHookManager: Deleting directory C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-d2f2337e-f45d-4717-81a6-241ff8f64e38
21/02/25 01:01:24 INFO ShutdownHookManager: Deleting directory C:\Users\tomyt\AppData\Local\spark\spark-3.0.1-bin-hadoop3.2\tmp\local\spark-d2f2337e-f45d-4717-81a6-241ff8f64e38\pyspark-3c2eaff3-1be4-4aaf-b48d-78b8cb44817d
